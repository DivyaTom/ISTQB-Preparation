Chapter 2: Testing Throughout the Software Development Lifecycle (SDLC) ðŸ”„ (130 minutes)
--------------------------------------------------------------------------------
This chapter shows how testing fits into different ways of building software.

2.1 Testing in the Context of a Software Development Lifecycle (SDLC)
---------------------------------------------------------------------
â€¢ An SDLC model is a high-level plan for how software is developed, showing how different steps connect. Examples include Waterfall (steps follow each other), Iterative (repeating cycles like Spiral), and Incremental (building in small parts like Unified Process).
â€¢ Agile practices like Scrum, Kanban, and Test-Driven Development (TDD) are more detailed ways of working.

2.1.1 How the SDLC Impacts Testing
--------------------------------------
The SDLC choice affects:
â€¢ What and when testing activities happen (e.g., test levels, types).
â€¢ How detailed test documents are.
â€¢ Which test techniques and approaches are used.
â€¢ How much automation is done.
â€¢ The tester's roles and responsibilities.
â€¢ For example, in Waterfall, dynamic testing usually happens later. In Agile, both static and dynamic testing can happen often in each small step, needing lots of automation for repeated tests.
2.1.2 Good Testing Practices for Any SDLC
----------------------------------------
No matter the SDLC, good testing usually involves:
â€¢ A test activity for every development activity to check quality.
â€¢ Each test level (see below) having clear and different goals to avoid wasted effort.
â€¢ Starting test analysis and design early.
â€¢ Testers reviewing documents early to find defects.
2.1.3 Testing as a Driver for Software Development
---------------------------------------------------
Some approaches use tests to guide development, starting tests before code. This helps with early testing and shift left:
â€¢ Test-Driven Development (TDD): Write tests first, then write code to pass those tests.
â€¢ Acceptance Test-Driven Development (ATDD): Tests are created from "acceptance criteria" (what the user needs) before the software is built to meet them.
â€¢ Behavior-Driven Development (BDD): Describes software behavior using simple, natural language tests (like "Given/When/Then").
2.1.4 DevOps and Testing
--------------------------
â€¢ DevOps means Development (including testing) and Operations teams working closely together.
â€¢ It aims for faster, higher-quality software releases through continuous integration (CI) and continuous delivery (CD) pipelines.
â€¢ Benefits for Testing:
    â—¦ Quick feedback on code quality.
    â—¦ Shift left promoted by CI (developers writing tests and using static analysis).
    â—¦ Easier to set up test environments.
    â—¦ Better view of non-functional quality (like speed, security).
    â—¦ Less manual repetitive testing due to automation.
    â—¦ Reduced risk of breaking existing features (regression).
â€¢ Risks/Challenges: Setting up and maintaining the DevOps pipeline, tools, and test automation takes resources. Manual testing is still needed, especially from a user's view.
2.1.5 Shift Left â€“ Test Earlier!
-----------------------------------
â€¢ This is the idea that testing should happen as early as possible in the SDLC.
â€¢ It doesn't mean stopping later testing, just starting earlier.
â€¢ How to "Shift Left":
    â—¦ Reviewing requirements early for problems.
    â—¦ Writing test cases before code is written.
    â—¦ Using CI/CD with automated tests.
    â—¦ Doing static analysis before dynamic testing.
    â—¦ Starting non-functional testing earlier, if possible.
â€¢ Shift left might cost more effort/money at first, but saves a lot later.
2.1.6 Retrospectives and Process Improvement
----------------------------------------------
â€¢ Retrospectives are meetings (often at project/iteration end) where the team discusses:
    â—¦ What went well.
    â—¦ What could be improved.
    â—¦ How to apply improvements in the future.
â€¢ They are key for continuous improvement.
â€¢ Benefits for Testing: More effective/efficient testing, better testware, improved team learning and cooperation.
2.2 Test Levels and Test Types
---------------------------------
â€¢ Test Levels: Groups of test activities that happen at different development stages (e.g., testing individual parts vs. the whole system).
â€¢ Test Types: Groups of test activities focused on specific quality characteristics (e.g., checking functions, or checking performance). Most test types can be done at any test level.
2.2.1 Different Test Levels
---------------------------
There are five main levels:
â€¢ Component Testing (Unit Testing): Testing individual parts of the software in isolation. Usually done by developers.
â€¢ Component Integration Testing (Unit Integration Testing): Testing the connections and interactions between components.
â€¢ System Testing: Testing the entire system's overall behavior and features, including how it works end-to-end and its non-functional aspects (like speed). Often done by an independent test team.
â€¢ System Integration Testing: Testing the connections between your system and other external systems or services.
â€¢ Acceptance Testing: Focused on validating that the system meets users' business needs and is ready to be used. Ideally, done by the actual users.
2.2.2 Different Test Types
---------------------------
Four key types are:
â€¢ Functional Testing: Checks "what" the software should do (e.g., does it calculate correctly?). Aims for completeness, correctness, and suitability of functions.
â€¢ Non-functional Testing: Checks "how well" the system behaves. This includes things like:
    â—¦ Performance efficiency (how fast it is).
    â—¦ Usability (interaction capability) (how easy it is to use).
    â—¦ Reliability (how consistently it works).
    â—¦ Security (how protected it is).
    â—¦ Maintainability (how easy it is to fix/change).
    â—¦ Portability (flexibility) (how easily it moves to new environments).
    â—¦ Safety. Non-functional testing can start early and is crucial because late defects can be very damaging.
â€¢ Black-Box Testing: Tests the software based on its external behavior or specifications, without knowing its internal code structure.
â€¢ White-Box Testing: Tests the software based on its internal structure or implementation (like code, architecture, data flow).
2.2.3 Confirmation Testing and Regression Testing
-------------------------------------------------
When software changes (e.g., new features or bug fixes), we need these tests:
â€¢ Confirmation Testing: Confirms that a fixed defect has actually been resolved. This usually means re-running the test that found the original bug.
â€¢ Regression Testing: Confirms that the changes or fixes haven't broken anything else in the system. These tests are often automated because they are run many times and grow over time.
2.3 Maintenance Testing
--------------------------
â€¢ This is testing done on an already existing, live system when changes are made (e.g., fixing bugs, adding new features, or updating the environment).
â€¢ It includes checking the new changes AND making sure old parts still work (regression testing).
â€¢ The amount of testing depends on the risk, size of the system, and size of the change.
